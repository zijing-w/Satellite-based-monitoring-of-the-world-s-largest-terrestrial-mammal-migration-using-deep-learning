{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4x9H2wJ1m7j"
   },
   "source": [
    "## Load libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65470,
     "status": "ok",
     "timestamp": 1660301119944,
     "user": {
      "displayName": "Juli Baker",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "rHYQ6yZ5R-TL",
    "outputId": "d2cc5def-1959-4c7a-a3cd-691deef49f12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting rasterio\n",
      "  Downloading rasterio-1.2.10-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.3 MB 462 kB/s \n",
      "\u001b[?25hCollecting cligj>=0.5\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
      "Collecting affine\n",
      "  Downloading affine-2.3.1-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.4.0)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (22.1.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2022.6.15)\n",
      "Collecting click-plugins\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.21.6)\n",
      "Collecting snuggs>=1.4.1\n",
      "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\n",
      "Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio\n",
      "Successfully installed affine-2.3.1 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.2.10 snuggs-1.4.7\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting geopandas\n",
      "  Downloading geopandas-0.10.2-py2.py3-none-any.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.3.5)\n",
      "Collecting fiona>=1.8\n",
      "  Downloading Fiona-1.8.21-cp37-cp37m-manylinux2014_x86_64.whl (16.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.7 MB 58.7 MB/s \n",
      "\u001b[?25hCollecting pyproj>=2.2.0\n",
      "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.3 MB 54.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (22.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
      "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
      "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
      "Collecting munch\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2022.6.15)\n",
      "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.21.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2022.1)\n",
      "Installing collected packages: munch, pyproj, fiona, geopandas\n",
      "Successfully installed fiona-1.8.21 geopandas-0.10.2 munch-2.5.0 pyproj-3.2.1\n"
     ]
    }
   ],
   "source": [
    "#If you are using Google Colaboratory to run this code, please upload the whole folder to your Google Drive, and run this cell install the requirements.\n",
    "\n",
    "#connect to the google drive if you use Google Colaboratory\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "#install the libraries\n",
    "!pip install rasterio\n",
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7663,
     "status": "ok",
     "timestamp": 1660301355176,
     "user": {
      "displayName": "Juli Baker",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "mW60uNlcTOd9",
    "outputId": "54728002-cb64-4af2-fa6f-0414cef0c675"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['maximum', 'dot', 'add', 'average', 'multiply', 'subtract', 'minimum', 'shape', 'concatenate', 'random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting ipython-autotime\n",
      "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
      "Installing collected packages: ipython-autotime\n",
      "Successfully installed ipython-autotime-0.3.1\n",
      "time: 166 µs (started: 2022-08-12 10:49:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 10)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from skimage import exposure\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD, Adadelta\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import os\n",
    "import rasterio \n",
    "#import rasterio.warp             # Reproject raster samples\n",
    "from rasterio import windows\n",
    "#import geopandas as gps\n",
    "#import PIL.Image\n",
    "#import PIL.ImageDraw\n",
    "import fiona \n",
    "import imageio\n",
    "from osgeo import gdal\n",
    "\n",
    "from shapely.geometry import Point, MultiPoint\n",
    "from shapely.geometry import mapping, shape\n",
    "import numpy as np               # numerical array manipulation\n",
    "#from tqdm import tqdm\n",
    "import cv2\n",
    "import random\n",
    "from rasterio.windows import Window\n",
    "from skimage import measure\n",
    "from sklearn.cluster import KMeans\n",
    "from fiona.crs import from_epsg\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 10)\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "!pip install ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2360,
     "status": "ok",
     "timestamp": 1660301357532,
     "user": {
      "displayName": "Juli Baker",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "1hoOpPmE1hl4",
    "outputId": "3d094550-e702-42ff-e6e1-e45d9b2080be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.55 s (started: 2022-08-12 10:49:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#set the sys path where the modules locates\n",
    "import sys\n",
    "sys.path.insert(0,\"code/core\")\n",
    "\n",
    "#If you are using Google Colaboratory, modify the path here\n",
    "sys.path.insert(0,\"/content/drive/MyDrive/Colab/Wildebeest-UNet/core\")\n",
    "\n",
    "#import modules\n",
    "import data_generator\n",
    "from data_generator import DataGenerator\n",
    "\n",
    "import data_augmentation\n",
    "from data_augmentation import *\n",
    "\n",
    "import counting\n",
    "from counting import *\n",
    "\n",
    "import visualization\n",
    "from visualization import *\n",
    "\n",
    "import importlib\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "def gridwise_sample2(imgarray, patchsize):\n",
    "    \"\"\"Extract sample patches of size patchsize x patchsize from an image (imgarray) in a gridwise manner.\n",
    "    \"\"\"\n",
    "    nrows, ncols, nbands = imgarray.shape\n",
    "    patchsamples = np.zeros(shape=(0, patchsize, patchsize, nbands),\n",
    "                            dtype=imgarray.dtype)\n",
    "    for i in range(int(nrows/patchsize)):\n",
    "        for j in range(int(ncols/patchsize)):\n",
    "            tocat = imgarray[i*patchsize:(i+1)*patchsize,\n",
    "                             j*patchsize:(j+1)*patchsize, :]\n",
    "            tocat = np.expand_dims(tocat, axis=0)\n",
    "            patchsamples = np.concatenate((patchsamples, tocat),\n",
    "                                          axis=0)\n",
    "    return patchsamples\n",
    "\n",
    "def linear_stretch(image):\n",
    "    C = image.shape\n",
    "    image2 = image.copy()\n",
    "    for i in range(image2.shape[2]):\n",
    "        p2, p98 = np.percentile(image2[:, :, i], (0.5, 99.5))\n",
    "        image2[:, :, i] = exposure.rescale_intensity(image2[:, :, i],\n",
    "                                                      in_range=(p2, p98))\n",
    "        \n",
    "    return image2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsAE_u0QpMfa"
   },
   "source": [
    "## Load the whole satellite image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1660301357533,
     "user": {
      "displayName": "Juli Baker",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "OfymUV4h3_pn",
    "outputId": "3132d7c6-200e-478f-cbd4-6f10f8f8225b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.23 ms (started: 2022-08-12 10:49:17 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#Define File directories\n",
    "Data_folder =  \"/SampleData/\"\n",
    "#If you are using Google Colaboratory, modify the path here\n",
    "Data_folder = \"/content/drive/MyDrive/Colab/Wildebeest-UNet/SampleData\"\n",
    "Folder = \"/content/drive/MyDrive/Colab/Wildebeest-UNet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1660301358013,
     "user": {
      "displayName": "Juli Baker",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "FklJP5wxgSv4",
    "outputId": "5d23847f-b967-43bb-dab1-d61a3d9d3d8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab/zijingwu-Satellite-based-monitoring-of-wildebeest/SampleData/data_2009Aug/classify/GE1_20090811_sample.tif\n",
      "time: 8.51 ms (started: 2022-08-12 10:49:17 +00:00)\n"
     ]
    }
   ],
   "source": [
    "CLASSIFY_PATH = os.path.join(Data_folder, \"data_2009Aug/classify\")\n",
    "img_name = 'GE1_20090811_sample'\n",
    "index = 'GE1_20090811_sample'\n",
    "image_dir = os.path.join(CLASSIFY_PATH, img_name+'.tif')\n",
    "\n",
    "print(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1660302259932,
     "user": {
      "displayName": "Juli Baker",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "782QHHejuPH5",
    "outputId": "9181b5bf-a9ba-4dc4-f894-d6f68c2aa18e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 0.43, 0.00, 718459.13|\n",
      "| 0.00,-0.43, 9857063.71|\n",
      "| 0.00, 0.00, 1.00|\n",
      "time: 892 ms (started: 2022-08-12 11:04:19 +00:00)\n"
     ]
    }
   ],
   "source": [
    "src = rasterio.open(image_dir)\n",
    "print(src.meta['transform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6301,
     "status": "ok",
     "timestamp": 1658935095164,
     "user": {
      "displayName": "Juli Baker",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "mMh7u6YTSPuN",
    "outputId": "bda56cc7-c5a5-4a50-bf4c-9999e79eff34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000, 4)\n",
      "time: 5.07 s (started: 2022-07-27 15:18:09 +00:00)\n"
     ]
    }
   ],
   "source": [
    "image_data=gdal.Open(image_dir)\n",
    "bands = [image_data.GetRasterBand(i+1).ReadAsArray() for i in range(image_data.RasterCount)]\n",
    "new_image = np.stack(bands, axis=2)\n",
    "del bands\n",
    "\n",
    "print(np.shape(new_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43662,
     "status": "ok",
     "timestamp": 1658935138819,
     "user": {
      "displayName": "Juli Baker",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "6MSNux6tS-Ly",
    "outputId": "3a91d767-3d5a-4cf1-94e7-f72ef3a16f97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 841 number of training patches\n",
      "time: 44.3 s (started: 2022-07-27 15:18:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "PATCHSIZE = 336\n",
    "NBANDS = new_image.shape[-1]\n",
    "classify_list = gridwise_sample2(new_image, PATCHSIZE)\n",
    "print(\"There are %i number of training patches\" % (classify_list.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1208,
     "status": "ok",
     "timestamp": 1658935140015,
     "user": {
      "displayName": "Juli Baker",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "F4DkGf0zTFZ5",
    "outputId": "a28a829e-2265-40cf-8ec4-5ba4a11e28f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.05 s (started: 2022-07-27 15:18:58 +00:00)\n"
     ]
    }
   ],
   "source": [
    "del new_image\n",
    "\n",
    "numpy.save(os.path.join(CLASSIFY_PATH, 'list'+img_name+'.npy'), classify_list, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQxlg_ALTK3J"
   },
   "source": [
    "## Classify the whole image and detect the wildebeest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1411,
     "status": "ok",
     "timestamp": 1658935448311,
     "user": {
      "displayName": "Juli Baker",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "QRPSVCVMT7o6",
    "outputId": "37688632-0412-466a-b174-eaac4489385c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(841, 336, 336, 4)\n",
      "255\n",
      "<class 'numpy.ndarray'>\n",
      "(841, 336, 336, 4)\n",
      "9744 9744\n",
      "time: 797 ms (started: 2022-07-27 15:24:07 +00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# #after converting to 8int data type\n",
    "# CLASSIFY_PATH = os.path.join(Data_folder, \"data_2009Aug/classify/\")\n",
    "# img_name = 'GE1_20090811_sample'\n",
    "# index = 'GE1_20090811_sample'\n",
    "# image_dir = os.path.join(CLASSIFY_PATH, img_name+'.tif')\n",
    "\n",
    "# print(image_dir)\n",
    "\n",
    "classify_list = np.load(os.path.join(CLASSIFY_PATH, 'list'+img_name+'.npy'))\n",
    "\n",
    "print(np.shape(classify_list))\n",
    "print(np.max(classify_list))\n",
    "# If the image is not in goog quality (low contrast), use the following function to add a linear contrast.\n",
    "# for i in range(classify_list.shape[0]):\n",
    "#     classify_list[i] = linear_stretch(classify_list[i])\n",
    "\n",
    "# print(np.max(classify_list))\n",
    "\n",
    "READ_CHANNEL = [1,2,3,4]\n",
    "# READ_CHANNEL = [1,2,3]\n",
    "NBANDS = len(READ_CHANNEL)\n",
    "classify_list = classify_list[:,:,:,0:NBANDS]\n",
    "\n",
    "print(type(classify_list))\n",
    "print(np.shape(classify_list))\n",
    "\n",
    "\n",
    "image_src=rasterio.open(image_dir)\n",
    "\n",
    "nrows = np.int(image_src.shape[0]/336)\n",
    "ncols = np.int(image_src.shape[1]/336)\n",
    "\n",
    "\n",
    "# The size in pixels of your desired window\n",
    "PATCHSIZE = 336\n",
    "xsize, ysize = PATCHSIZE*ncols, PATCHSIZE*nrows\n",
    "\n",
    "# Create a Window and calculate the transform from the source dataset    \n",
    "window = Window(0, 0, xsize, ysize)\n",
    "transform = image_src.window_transform(window)\n",
    "\n",
    "# Create a new cropped raster to write to\n",
    "profile = image_src.profile\n",
    "profile.update({\n",
    "    'height': ysize,\n",
    "    'width': xsize,\n",
    "    'transform': transform})\n",
    "\n",
    "print(xsize, ysize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1658935456128,
     "user": {
      "displayName": "Juli Baker",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "MONhAe69UmFY",
    "outputId": "ba15f35e-93bd-4053-d8b9-62d9a3e60b24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 268 ms (started: 2022-07-27 15:24:15 +00:00)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Classify the patches\n",
    "WEIGHT_PATH = os.path.join(Folder, 'tmp/pretrained_weights')\n",
    "\n",
    "#    Edited by Sizhuo Li\n",
    "#    Author: Ankit Kariryaa, University of Bremen\n",
    "#Tversky loss function, which assigns more weights to false positive/false negative by adjusting alpha and beta parameters\n",
    "def tversky(y_true, y_pred, alpha=0.1, beta=0.9):\n",
    "    \"\"\"\n",
    "    Function to calculate the Tversky loss for imbalanced data\n",
    "    :param prediction: the logits\n",
    "    :param ground_truth: the segmentation ground_truth\n",
    "    :param alpha: weight of false positives\n",
    "    :param beta: weight of false negatives\n",
    "    :param weight_map:\n",
    "    :return: the loss\n",
    "    \"\"\"\n",
    "    '''\n",
    "\n",
    "    EPSILON = 0.00001\n",
    "    '''\n",
    "    y_true_pos = K.flatten(y_true)\n",
    "    y_pred_pos = K.flatten(y_pred)\n",
    "    # TP\n",
    "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
    "    # FN\n",
    "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
    "    # FP\n",
    "    false_pos = K.sum((1-y_true_pos) * y_pred_pos)\n",
    "    return 1 - (true_pos + K.epsilon())/(true_pos + alpha * false_neg + beta * false_pos + K.epsilon())\n",
    "\n",
    "def accuracy(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"compute accuracy\"\"\"\n",
    "    y_t = y_true[...,0]\n",
    "    y_t = y_t[...,np.newaxis]\n",
    "    y_pred = K.round(y_pred +0.5 - threshold)\n",
    "    return K.equal(K.round(y_t), K.round(y_pred))\n",
    "\n",
    "\n",
    "# K.round() returns the Element-wise rounding to the closest integer!!!\n",
    "# so the threshold to determine a true positive is here!!!!!\n",
    "def true_positives(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"compute true positive\"\"\"\n",
    "    #y_t = y_true[...,0]\n",
    "    #y_t = y_t[...,np.newaxis]\n",
    "    y_pred = K.round(y_pred +0.5 - threshold)\n",
    "    return K.round(y_true * y_pred)\n",
    "\n",
    "def false_positives(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"compute false positive\"\"\"\n",
    "    #y_t = y_true[...,0]\n",
    "    #y_t = y_t[...,np.newaxis]\n",
    "    y_pred = K.round(y_pred +0.5 - threshold)\n",
    "    return K.round((1 - y_true) * y_pred)\n",
    "\n",
    "def true_negatives(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"compute true negative\"\"\"\n",
    "    #y_t = y_true[...,0]\n",
    "    #y_t = y_t[...,np.newaxis]\n",
    "    y_pred = K.round(y_pred +0.5 - threshold)\n",
    "    return K.round((1 - y_true) * (1 - y_pred))\n",
    "\n",
    "def false_negatives(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"compute false negative\"\"\"\n",
    "    #y_t = y_true[...,0]\n",
    "    #y_t = y_t[...,np.newaxis]\n",
    "    y_pred = K.round(y_pred +0.5 - threshold)\n",
    "    return K.round((y_true) * (1 - y_pred))\n",
    "def recall_m(y_true, y_pred):\n",
    "    #y_t = y_true[...,0]\n",
    "    #y_t = y_t[...,np.newaxis]\n",
    "    tp = true_positives(y_true, y_pred)\n",
    "    fn = false_negatives(y_true, y_pred)\n",
    "    recall = K.sum(tp) / (K.sum(tp) + K.sum(fn)+ K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    #y_t = y_true[...,0]\n",
    "    #y_t = y_t[...,np.newaxis]\n",
    "    tp = true_positives(y_true, y_pred)\n",
    "    fp = false_positives(y_true, y_pred)\n",
    "    precision = K.sum(tp) / (K.sum(tp) + K.sum(fp)+ K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "#Model builder\n",
    "#    Author: Ankit Kariryaa, University of Bremen\n",
    "#!pip install tensorflow-estimatior==2.1.0\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, Adagrad, Nadam\n",
    "\n",
    "def unet(pretrained_weights = None,input_size = (PATCHSIZE,PATCHSIZE,NBANDS),lr = 1.0e-04, weight_b = 0.9, regularizers = regularizers.l2(0.0001)):\n",
    "    inputs = Input(input_size)\n",
    "    #conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    norm1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(norm1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    norm2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(norm2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    norm3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(norm3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    norm4 = BatchNormalization()(conv4)\n",
    "    drop4 = Dropout(0.5)(norm4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    norm6 = BatchNormalization()(up6)\n",
    "    merge6 = Concatenate(axis = 3)([drop4, norm6])\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    norm7 = BatchNormalization()(up7)\n",
    "    merge7 = Concatenate(axis = 3)([norm3,norm7])\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    norm8 = BatchNormalization()(up8)\n",
    "    merge8 = Concatenate(axis = 3)([norm2,norm8])\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    norm9 = BatchNormalization()(up9)\n",
    "    merge9 = Concatenate(axis = 3)([norm1,norm9])\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid', kernel_regularizer= regularizers)(conv9)\n",
    "    # set the probablity threshold that determines the wildebeest existence\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "    #model.compile(optimizer = Adam(lr = 1e-4), loss =BinaryFocalLoss(gamma=2.0, pos_weight=0.25), metrics = ['accuracy', recall_m, precision_m, f1_m])\n",
    "    \n",
    "    #Tree count code\n",
    "    OPTIMIZER = Adam(learning_rate = lr, beta_1= 0.9, beta_2= 0.999, epsilon= 1.0e-8)\n",
    "    LOSS = tversky\n",
    "\n",
    "\n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[accuracy, precision_m, recall_m, f1_m])\n",
    "    #model.summary()\n",
    "\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 460897,
     "status": "ok",
     "timestamp": 1658935918650,
     "user": {
      "displayName": "Juli Baker",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "kGFmd99sVL-H",
    "outputId": "2ce009d7-52ac-40b0-c2e4-e5baee4b3f08"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(841, 336, 336, 1)\n",
      "1\n",
      "(841, 336, 336, 1)\n",
      "2\n",
      "(841, 336, 336, 1)\n",
      "3\n",
      "(841, 336, 336, 1)\n",
      "4\n",
      "(841, 336, 336, 1)\n",
      "5\n",
      "(841, 336, 336, 1)\n",
      "6\n",
      "(841, 336, 336, 1)\n",
      "7\n",
      "(841, 336, 336, 1)\n",
      "8\n",
      "(841, 336, 336, 1)\n",
      "9\n",
      "(841, 336, 336, 1)\n",
      "10\n",
      "1.0\n",
      "0.0\n",
      "int8\n",
      "(841, 336, 336, 1)\n",
      "time: 7min 40s (started: 2022-07-27 15:24:17 +00:00)\n"
     ]
    }
   ],
   "source": [
    "weight_set = 0.9\n",
    "lr_set = 1e-4\n",
    "\n",
    "num_folds = 10\n",
    "Ypredict = [0]\n",
    "\n",
    "for i in range(num_folds):\n",
    "    model = unet(pretrained_weights=None, input_size=(PATCHSIZE,PATCHSIZE,NBANDS), lr = lr_set, weight_b = weight_set, regularizers = regularizers.l2(0.0001))\n",
    "    best_path = os.path.join(WEIGHT_PATH, 'best_weights_fold_' + str(i+1) + '.hdf5')\n",
    "    model.load_weights(best_path)\n",
    "    predict = model.predict(classify_list)\n",
    "    if np.max(predict) > 0.05:\n",
    "      predict = (predict-np.min(predict))/(np.max(predict)-np.min(predict))\n",
    "    print(np.shape(predict))\n",
    "    Ypredict += predict\n",
    "    del predict\n",
    "  \n",
    "    print(i+1)\n",
    "    \n",
    "\n",
    "predict = Ypredict/10\n",
    "del Ypredict\n",
    "\n",
    "print(np.max(predict))\n",
    "print(np.min(predict))\n",
    "predict[predict>0.5]=1.0\n",
    "predict[predict<=0.5]=0.0\n",
    "predict = predict.astype(np.int8)\n",
    "\n",
    "print(predict.dtype)\n",
    "print(np.shape(predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44996,
     "status": "ok",
     "timestamp": 1658935963632,
     "user": {
      "displayName": "Juli Baker",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "ARzWLRxy1hl7",
    "outputId": "f31f7f23-42f5-4043-e1c6-32368539661d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29 9744 9744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9744, 9744, 1)\n",
      "{'driver': 'GTiff', 'dtype': 'int8', 'nodata': None, 'width': 9744, 'height': 9744, 'count': 1, 'crs': CRS.from_epsg(4326), 'transform': Affine(0.4296371999999508, 0.0, 718459.127,\n",
      "       0.0, -0.4296371999999508, 9857063.7052)}\n",
      "41331\n",
      "41331\n",
      "time: 44.7 s (started: 2022-07-27 15:31:58 +00:00)\n"
     ]
    }
   ],
   "source": [
    "image_src=rasterio.open(image_dir)\n",
    "\n",
    "nrows = np.int(image_src.shape[0]/336)\n",
    "ncols = np.int(image_src.shape[1]/336)\n",
    "\n",
    "# The size in pixels of your desired window\n",
    "PATCHSIZE = 336\n",
    "xsize, ysize = PATCHSIZE*ncols, PATCHSIZE*nrows\n",
    "\n",
    "print(nrows, ncols, xsize, ysize)\n",
    "\n",
    "classified_image = np.zeros(shape=(0, xsize, 1),dtype=predict.dtype)\n",
    "\n",
    "for i in range(nrows):\n",
    "  image_row = np.concatenate(predict[ncols*i:ncols*(i+1),:,:,:], axis = 1)\n",
    "  classified_image = np.concatenate((classified_image, image_row), axis = 0)\n",
    "\n",
    "print(np.shape(classified_image))\n",
    "del predict\n",
    "\n",
    "\n",
    "from osgeo import osr              ###\n",
    "srs = osr.SpatialReference()       ###\n",
    "srs.SetFromUserInput(\"EPSG:32736\")  ###\n",
    "# srs.SetFromUserInput(\"EPSG:4326\")  ###\n",
    "wgs84 = srs.ExportToProj4() \n",
    "\n",
    "#no use\n",
    "profile = image_src.profile\n",
    "profile.update({\n",
    "    'crs': wgs84})\n",
    "\n",
    "transform = image_src.meta['transform']\n",
    "crs = image_src.meta['crs']\n",
    "\n",
    "new_dataset = rasterio.open(os.path.join(CLASSIFY_PATH, index+'classifiedInt.tif'), 'w', driver='GTiff',\n",
    "                            height = classified_image.shape[0], width = classified_image.shape[1],\n",
    "                            count=1, dtype=str(classified_image.dtype),\n",
    "                            crs=wgs84,\n",
    "                            transform=transform)\n",
    "\n",
    "new_dataset.write(classified_image[:,:,0],1)\n",
    "new_dataset.close()\n",
    "\n",
    "del image_row\n",
    "del classified_image\n",
    "\n",
    "from osgeo import osr              ###\n",
    "srs = osr.SpatialReference()       ###\n",
    "srs.SetFromUserInput(\"EPSG:32736\")  ###\n",
    "# srs.SetFromUserInput(\"EPSG:4326\")  ###\n",
    "wgs84 = srs.ExportToProj4() \n",
    "\n",
    "schema = {\n",
    "    'geometry': 'Point',\n",
    "    'properties': {'id': 'str'},\n",
    "    }\n",
    "def createShapefileObject(points, meta, wfile):\n",
    "    #with fiona.open(wfile, 'w', crs=meta.get('crs').to_dict(), driver='ESRI Shapefile', schema=schema) as sink:\n",
    "    with fiona.open(wfile, 'w', crs=wgs84, driver='ESRI Shapefile', schema=schema) as sink:\n",
    "        for idx, point in enumerate(points):\n",
    "            sink.write({\n",
    "                'geometry': mapping(point),\n",
    "                'properties': {'id': str(idx)},\n",
    "                })\n",
    "            #print(mapping(point))\n",
    "\n",
    "classified_src = rasterio.open(os.path.join(CLASSIFY_PATH, index+'classifiedInt.tif'))\n",
    "print(classified_src.meta)\n",
    "\n",
    "image = classified_src.read() #shape of image is (1, rows, cols)\n",
    "image = image[0,:,:]\n",
    "all_points = ImageToPoints(image, classified_src)\n",
    "print(len(all_points)) \n",
    "count = len(all_points)\n",
    "\n",
    "createShapefileObject(all_points, classified_src.meta, os.path.join(CLASSIFY_PATH, index+'.shp'))\n",
    "\n",
    "import pandas as pd\n",
    "k = 1\n",
    "print(count)\n",
    "uncertainty = {}\n",
    "uncertainty['ID'] = img_name\n",
    "uncertainty['k'] = k\n",
    "uncertainty['count'] = count\n",
    "results = pd.DataFrame(uncertainty, index=[0])\n",
    "results.to_csv(os.path.join(CLASSIFY_PATH, index+'_count.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1658935963633,
     "user": {
      "displayName": "Juli Baker",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "WG6oRXm91hmR",
    "outputId": "71df8702-f4a7-4812-81cf-e39c97b0d233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41331\n",
      "time: 910 µs (started: 2022-07-27 15:32:43 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fT_9NF_jzLJ1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "3_Postprocessing_ wildebeest_counting.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
